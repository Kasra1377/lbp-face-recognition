{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"face.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1vjDE0aLxyVvUWL1xbTojCdFp7RrHUAXp","authorship_tag":"ABX9TyMyIc8Ltx2nF4xmULfC+V4S"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"FcbE59ndQOtO","executionInfo":{"status":"ok","timestamp":1631278593520,"user_tz":-270,"elapsed":524,"user":{"displayName":"Kasra Sadeghianpoor","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-M-IQfCdV1sDtftP0aqLtsS4eCJ8Pzr5Ka4Ee=s64","userId":"12889102283785354184"}}},"source":["from imutils import paths\n","import numpy as np\n","import imutils\n","import cv2\n","import os"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"pugxlfiIWZiN","executionInfo":{"status":"ok","timestamp":1631278594081,"user_tz":-270,"elapsed":4,"user":{"displayName":"Kasra Sadeghianpoor","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-M-IQfCdV1sDtftP0aqLtsS4eCJ8Pzr5Ka4Ee=s64","userId":"12889102283785354184"}}},"source":["def face_detection(image):\n","  cascadePath = \"haarcascade_frontalface_default.xml\"\n","  detector = cv2.CascadeClassifier(cascadePath)\n","\n","  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","  rects = detector.detectMultiScale(gray, scaleFactor=1.05,\n","\tminNeighbors=10, minSize=(30, 30),\n","\tflags=cv2.CASCADE_SCALE_IMAGE)\n","\n","  return rects"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"LdnHJaxtW7HN","executionInfo":{"status":"ok","timestamp":1631278594082,"user_tz":-270,"elapsed":3,"user":{"displayName":"Kasra Sadeghianpoor","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-M-IQfCdV1sDtftP0aqLtsS4eCJ8Pzr5Ka4Ee=s64","userId":"12889102283785354184"}}},"source":["def load_face_dataset(inputPath, minSamples = 15):\n","  # get all the image paths in the dataset folder structure and grab \n","  # the name(i.e. groundtruth) of all the images and count each of them\n","  # and then put all of the groundtruths into a list\n","  imagePaths = list(paths.list_images(inputPath))\n","  names = [p.split(os.path.sep)[-2] for p in imagePaths]\n","  (names , counts) = np.unique(names , return_counts = True)\n","  names = names.tolist()\n","\n","  faces = []\n","  labels = []\n","\n","  # loop over all of the image paths\n","  for imagePath in imagePaths:\n","    # read the image and grab the image label\n","    image = cv2.imread(imagePath)\n","    name = imagePath.split(os.path.sep)[-2]\n","\n","    # check whether the count of this specific label is\n","    # below our minSamples threshold or not\n","    if counts[names.index(name)] < minSamples:\n","      continue\n","    \n","    # perform face detection\n","    boxes = face_detection(image)\n","    \n","    # loop over the bounding boxes\n","    for (x , y , w , h) in boxes:\n","      try:\n","        # extract the face ROI, resize it and convert\n","        # it into grayscale format\n","        faceROI = image[y:y+h , x:x+w]\n","        faceROI = cv2.resize(faceROI , (47 , 62))\n","        faceROI = cv2.cvtColor(faceROI , cv2.COLOR_BGR2GRAY)\n","\n","        # update the faces and labels list\n","        faces.append(faceROI)\n","        labels.append(name)\n","      except:\n","        continue\n","  # convert the faces and labels lists into Numpy array\n","  faces = np.array(faces)\n","  labels = np.array(labels)\n","\n","  return (faces , labels)"],"execution_count":3,"outputs":[]}]}